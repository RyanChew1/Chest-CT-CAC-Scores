{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BASELINE - UNET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "Type info here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Support\n",
    "try: \n",
    "    import pydicom as dcm\n",
    "except:\n",
    "    # Use try except for Google Colab\n",
    "    !pip install pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "# Base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# SK-learn\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Files\n",
    "import os\n",
    "from os.path import join, split\n",
    "from glob import glob\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d, MaxPool2d, ReLU, ConvTranspose2d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torchvision.transforms import CenterCrop\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import tempfile\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed.fsdp import CPUOffload, wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3062"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"Numpy Dataset\\\\all\\images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    random_seed = 42\n",
    "    gated = True\n",
    "    path = \"Coronary CT Data\\Gated_release_final\" if gated else \"Coronary CT Data/deidentified_nongated\"\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_new = True\n",
    "    model_num = len(os.listdir(\"Models\")) if train_new else len(os.listdir(\"Models\"))-1\n",
    "\n",
    "    batch_size = 8\n",
    "    nEpochs = 10\n",
    "    lr = 0.1\n",
    "\n",
    "    TH = 0.8\n",
    "\n",
    "    model_name = f\"baseline_{model_num}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2518"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=CFG.random_seed):\n",
    "    print(f\"Seed: {seed}\")\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXML(xmlfile): \n",
    "    # create element tree object \n",
    "    tree = ET.parse(xmlfile) \n",
    "\n",
    "    all_images = []\n",
    "\n",
    "    images = tree.find(\"dict\").find(\"array\")\n",
    "    images = images.findall(\"dict\")\n",
    "\n",
    "    # Images\n",
    "    for image in images:\n",
    "        image_data = {}\n",
    "        arr = [i.text for i in image if i.tag not in [\"array\", \"dict\"]]\n",
    "        \n",
    "        for i in range(len(arr)//2):\n",
    "            image_data[arr[2*i]] = arr[2*i+1]\n",
    "\n",
    "        image_data['ROIs'] = []\n",
    "\n",
    "        # ROI\n",
    "        all_roi = image.find(\"array\").findall('dict')\n",
    "        for roi in all_roi:\n",
    "            roi_data = {}\n",
    "            arr = [i.text for i in roi if i.tag not in [\"array\", \"dict\"]]\n",
    "        \n",
    "            for i in range(len(arr)//2):\n",
    "                roi_data[arr[2*i]] = arr[2*i+1]\n",
    "\n",
    "            all_points = roi.findall('array')\n",
    "            roi_data['point_mm'] = [i.text for i in all_points[0].findall(\"string\")]\n",
    "            roi_data['point_px'] = [i.text for i in all_points[1].findall(\"string\")]\n",
    "            \n",
    "            image_data['ROIs'].append(roi_data)\n",
    "        all_images.append(image_data)\n",
    "\n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments(image_array, points):\n",
    "    polygon = Polygon(points, closed=True, edgecolor='r', facecolor='r')\n",
    "    polygon_indices = np.array(points)\n",
    "    polygon_indices[:, 0] = np.clip(polygon_indices[:, 0], 0, 511)\n",
    "    polygon_indices[:, 1] = np.clip(polygon_indices[:, 1], 0, 511)\n",
    "    image_array[polygon_indices[:, 1], polygon_indices[:, 0]] = 1\n",
    "    polygon_path = Path(polygon_indices)\n",
    "    x, y = np.meshgrid(np.arange(512), np.arange(512))\n",
    "    points = np.column_stack((x.flatten(), y.flatten()))\n",
    "    mask = polygon_path.contains_points(points).reshape(512, 512)\n",
    "    image_array[mask] = 1\n",
    "\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, dir):\n",
    "        super().__init__()\n",
    "        self.dir = dir\n",
    "        self.images_path = join(dir, \"images\")\n",
    "        self.labels_path = join(dir, \"labels\")\n",
    "        self.images = os.listdir(self.images_path)\n",
    "        self.labels = os.listdir(self.labels_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx): # Return tuple (x, y)\n",
    "        try:\n",
    "            img = np.load(join(self.images_path, self.images[idx]), allow_pickle=True)\n",
    "            img = img.reshape(1, 512, 512) # Hard coded since all images are 512, 512\n",
    "\n",
    "            label = np.load(join(self.labels_path, self.labels[idx]), allow_pickle=True)\n",
    "            label = label.reshape(1, 512, 512)\n",
    "        except:\n",
    "            img, label = np.zeros((1,512,512), np.float32),np.zeros((1,512,512), np.float32)\n",
    "        return  img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CTDataset(\"Numpy Dataset\\\\train\")\n",
    "valid = CTDataset(\"Numpy Dataset\\\\valid\")\n",
    "test = CTDataset(\"Numpy Dataset\\\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDL = DataLoader(train, batch_size=CFG.batch_size,shuffle=True, pin_memory=True)\n",
    "validDL = DataLoader(valid, batch_size=CFG.batch_size)\n",
    "testDL = DataLoader(test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2380\n",
      "Valid: 1245\n",
      "Test: 377\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Valid: {len(valid)}\")\n",
    "print(f\"Test: {len(test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.relu  = ReLU()\n",
    "        self.conv2 = Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        # init random weights\n",
    "        nn.init.xavier_normal_(self.conv1.weight)\n",
    "        nn.init.zeros_(self.conv1.bias)\n",
    "\n",
    "        nn.init.xavier_normal_(self.conv2.weight)\n",
    "        nn.init.zeros_(self.conv2.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv2(self.relu(self.conv1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, channels = (1,32,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.pool = MaxPool2d((2,2))\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            Block(channels[i], channels[i+1]) for i in range(len(channels)-1) # 1, 32, ..., 1024\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = []\n",
    "        for block in self.encoder: # Goes through all blocks, passes through block and saves skip output\n",
    "            x = block(x)\n",
    "            skip_out.append(x)\n",
    "            x = self.pool(x) # Reduces dim\n",
    "        return skip_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDecoder(nn.Module):\n",
    "    def __init__(self, channels = (1,32,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.channels = channels[:0:-1] # Reverse of Encoder (Excluding First Unneeded in Output)\n",
    "        self.pool = MaxPool2d((2,2))\n",
    "        self.upconv = nn.ModuleList([\n",
    "            ConvTranspose2d(self.channels[i], self.channels[i+1], 2, 2) for i in range(len(self.channels)-1)\n",
    "        ])\n",
    "\n",
    "        self.decoder = nn.ModuleList([\n",
    "            Block(self.channels[i], self.channels[i+1]) for i in range(len(self.channels)-1)\n",
    "        ])\n",
    "\n",
    "    def center_crop(self, x, enc_out): # Crop encoder output\n",
    "        _, _, h, w = x.shape\n",
    "        enc_out = CenterCrop([h,w])(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def forward(self, x, enc_out:list):\n",
    "        for i in range(len(self.channels)-1):\n",
    "            x = self.upconv[i](x)\n",
    "            enc_ftrs = self.center_crop(x, enc_out[i]) # Crop Skip\n",
    "            x = torch.cat([x, enc_ftrs], dim=1) # Concatenate Decoder and Skip\n",
    "            x = self.decoder[i](x)\n",
    "\n",
    "            # Min Max Scaling [0,1]\n",
    "            x = (x-x.min())/(x.max()-x.min())\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self, channels = (1,32,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder Path\n",
    "        self.enc_path = AutoEncoder(channels)\n",
    "\n",
    "        # Decoder Path\n",
    "        self.dec_path = AutoDecoder(channels)\n",
    "\n",
    "        self.out = Conv2d(channels[1], 1, 1)\n",
    "\n",
    "        # init random weights\n",
    "        nn.init.xavier_normal_(self.out.weight)\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skips = self.enc_path(x)\n",
    "        x = self.dec_path(skips[::-1][0], skips[::-1][1:]) \n",
    "        # Reverse of enc_out = upward path of decoder \n",
    "        #  [0] -> 1024 output\n",
    "        # [1:] -> All other skip outputs\n",
    "        x = self.out(x)\n",
    "        # x = F.interpolate(x, (512,512))\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET().to(CFG.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.train_new:\n",
    "    try:\n",
    "        model = torch.load(f\"Models/{CFG.model_name}/{CFG.model_name}.pt\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model not found in models folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_10\n"
     ]
    }
   ],
   "source": [
    "print(CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(model.parameters(), lr=CFG.lr) # AdamW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sørensen–Dice coefficient:\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)\n",
    "</br>\n",
    "$${\\displaystyle DSC={\\frac {2|X\\cap Y|}{|X|+|Y|}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diceCoef(nn.Module):\n",
    "    def init(self):\n",
    "        super(diceCoef, self).init()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #intersection is equivalent to True Positive count\n",
    "        #union is the mutually inclusive area of all labels & predictions \n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = (inputs + targets).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "                \n",
    "        return 1 - IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_dice = DiceBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_iou = IoULoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pixel Binary\n",
    "* IOU\n",
    "* BCE Dice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter_ranges = {\n",
    "    'lr': (0.001, 0.3),\n",
    "    'batch_size': (16, 32),\n",
    "}\n",
    "\n",
    "# Step 3: Define the search space\n",
    "search_space = {\n",
    "    'lr': lambda: 10 ** (-3 * torch.rand(1)),\n",
    "    'batch_size': lambda: torch.randint(16, 33, (1,)).item(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_model(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(CFG.device), target.to(CFG.device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion_dice(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate_model(model, val_loader, b_size):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(CFG.device), target.to(CFG.device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion_dice(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    accuracy = correct / (len(val_loader.dataset)//b_size)\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_random_samples = 5\n",
    "best_accuracy = 0\n",
    "best_loss = 1000\n",
    "best_hyperparameters = None\n",
    "weights = None\n",
    "for _ in range(num_random_samples):\n",
    "    hyperparameters = {param: sampler() for param, sampler in search_space.items()}\n",
    "    model = UNET().to(CFG.device)\n",
    "    optimizer = AdamW(model.parameters(), lr=float(hyperparameters['lr']))\n",
    "    train_loader = DataLoader(train, batch_size=hyperparameters['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(valid, batch_size=hyperparameters['batch_size'], shuffle=False)\n",
    "\n",
    "    for epoch in range(5): # Run 5 epochs on each\n",
    "        train_model(model, train_loader, optimizer)\n",
    "    \n",
    "    val_loss, accuracy = evaluate_model(model, val_loader,hyperparameters['batch_size'])\n",
    "    if val_loss < best_loss:\n",
    "        weights = model.state_dict\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = hyperparameters\n",
    "        best_loss = val_loss\n",
    "\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "print(\"Lowest Loss:\", best_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\"train\":[],\n",
    "           \"valid\":[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = UNET().to(CFG.device)\n",
    "optim = AdamW(model.parameters(), lr=float(best_hyperparameters['lr']))\n",
    "trainDL = DataLoader(train, batch_size=best_hyperparameters['batch_size'], shuffle=True)\n",
    "validDL = DataLoader(valid, batch_size=best_hyperparameters['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [03:43<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.701959252357483\n",
      "Validation Dice Loss: 1.6927014589309692\n",
      "Validation IOU Loss: 0.9996717572212219\n",
      "[INFO] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [03:26<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6927334070205688\n",
      "Validation Dice Loss: 1.6924914121627808\n",
      "Validation IOU Loss: 0.9996717572212219\n",
      "[INFO] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/298 [02:00<02:10,  1.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m iou_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m tqdm(trainDL):\n\u001b[1;32m----> 9\u001b[0m     x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mto(CFG\u001b[39m.\u001b[39;49mdevice), y\u001b[39m.\u001b[39mto(CFG\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     10\u001b[0m     optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m     pred \u001b[39m=\u001b[39m model(x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(CFG.nEpochs):\n",
    "    print(f\"[INFO] Epoch {e+1}/{CFG.nEpochs}\")\n",
    "    \n",
    "    train_loss = 0\n",
    "    dice_loss = 0\n",
    "    iou_loss = 0\n",
    "    for x,y in tqdm(trainDL):\n",
    "        x, y = x.to(CFG.device), y.to(CFG.device)\n",
    "        optim.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion_dice(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss += loss\n",
    "    # eval\n",
    "    with torch.no_grad():\n",
    "        for x,y in validDL:\n",
    "            x, y = x.to(CFG.device), y.to(CFG.device)\n",
    "            pred = model(x)\n",
    "            loss_dice = criterion_dice(pred, y)\n",
    "            loss_iou = criterion_iou(pred, y)\n",
    "            dice_loss += loss_dice\n",
    "            iou_loss += loss_iou\n",
    "\n",
    "        \n",
    "    avg_train_loss = train_loss/len(trainDL)\n",
    "    avg_dice_loss = dice_loss/len(validDL)\n",
    "    avg_iou_loss = iou_loss/len(validDL)\n",
    "    \n",
    "    print(f\"Train Loss: {avg_train_loss}\")\n",
    "    print(f\"Validation Dice Loss: {avg_dice_loss}\")\n",
    "    print(f\"Validation IOU Loss: {avg_iou_loss}\")\n",
    "    history[\"train\"].append(avg_train_loss)\n",
    "    history['valid'].append(avg_dice_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folder \n",
    "\n",
    "\n",
    "Models\\\\model_name\\\\\n",
    "\n",
    "For Each Training\n",
    "Models\\\\baseline_0\\\\baseline_0.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.train_new:\n",
    "    os.mkdir(f\"Models/{CFG.model_name}\")\n",
    "    os.mkdir(f\"Models/{CFG.model_name}/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m log_num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModels/\u001b[39m\u001b[39m{\u001b[39;00mCFG\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/logs\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModels/\u001b[39m\u001b[39m{\u001b[39;00mCFG\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/logs/log_\u001b[39m\u001b[39m{\u001b[39;00mlog_num\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m out_path:\n\u001b[1;32m----> 4\u001b[0m     json\u001b[39m.\u001b[39;49mdump(history, out_path)\n",
      "File \u001b[1;32mc:\\Users\\chewr\\anaconda3\\envs\\tf\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(skipkeys\u001b[39m=\u001b[39mskipkeys, ensure_ascii\u001b[39m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[39m=\u001b[39mcheck_circular, allow_nan\u001b[39m=\u001b[39mallow_nan, indent\u001b[39m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[39m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[39m=\u001b[39mdefault, sort_keys\u001b[39m=\u001b[39msort_keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\u001b[39m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[39m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mc:\\Users\\chewr\\anaconda3\\envs\\tf\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chewr\\anaconda3\\envs\\tf\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chewr\\anaconda3\\envs\\tf\\lib\\json\\encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 325\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[0;32m    326\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chewr\\anaconda3\\envs\\tf\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[0;32m    439\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chewr\\anaconda3\\envs\\tf\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Save History as JSON\n",
    "log_num = len(os.listdir(f\"Models/{CFG.model_name}/logs\"))\n",
    "with open(f\"Models/{CFG.model_name}/logs/log_{log_num}\", \"w\") as out_path:\n",
    "    json.dump(history, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"Models/{CFG.model_name}/{CFG.model_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropout\n",
    "* Pixel Level Accuracy\n",
    "* Single Conv in Block (Save Memory)\n",
    "* Check Zoom\n",
    "* 3D UNET"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
