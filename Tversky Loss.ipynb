{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BASELINE - UNET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "Type info here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Support\n",
    "try: \n",
    "    import pydicom as dcm\n",
    "except:\n",
    "    # Use try except for Google Colab\n",
    "    !pip install pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "# Base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# SK-learn\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Files\n",
    "import os\n",
    "from os.path import join, split\n",
    "from glob import glob\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d, MaxPool2d, ReLU, ConvTranspose2d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torchvision.transforms import CenterCrop\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import tempfile\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed.fsdp import CPUOffload, wrap\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cu121'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7547"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"Numpy Dataset\\\\all\\images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    random_seed = 42\n",
    "    gated = True\n",
    "    path = \"Coronary CT Data\\Gated_release_final\" if gated else \"Coronary CT Data/deidentified_nongated\"\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_new = True\n",
    "    model_num = len(os.listdir(\"Models\")) if train_new else len(os.listdir(\"Models\"))-1\n",
    "\n",
    "    batch_size = 8\n",
    "    nEpochs = 100\n",
    "    lr = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20564"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=CFG.random_seed):\n",
    "    print(f\"Seed: {seed}\")\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXML(xmlfile): \n",
    "    # create element tree object \n",
    "    tree = ET.parse(xmlfile) \n",
    "\n",
    "    all_images = []\n",
    "\n",
    "    images = tree.find(\"dict\").find(\"array\")\n",
    "    images = images.findall(\"dict\")\n",
    "\n",
    "    # Images\n",
    "    for image in images:\n",
    "        image_data = {}\n",
    "        arr = [i.text for i in image if i.tag not in [\"array\", \"dict\"]]\n",
    "        \n",
    "        for i in range(len(arr)//2):\n",
    "            image_data[arr[2*i]] = arr[2*i+1]\n",
    "\n",
    "        image_data['ROIs'] = []\n",
    "\n",
    "        # ROI\n",
    "        all_roi = image.find(\"array\").findall('dict')\n",
    "        for roi in all_roi:\n",
    "            roi_data = {}\n",
    "            arr = [i.text for i in roi if i.tag not in [\"array\", \"dict\"]]\n",
    "        \n",
    "            for i in range(len(arr)//2):\n",
    "                roi_data[arr[2*i]] = arr[2*i+1]\n",
    "\n",
    "            all_points = roi.findall('array')\n",
    "            roi_data['point_mm'] = [i.text for i in all_points[0].findall(\"string\")]\n",
    "            roi_data['point_px'] = [i.text for i in all_points[1].findall(\"string\")]\n",
    "            \n",
    "            image_data['ROIs'].append(roi_data)\n",
    "        all_images.append(image_data)\n",
    "\n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments(image_array, points):\n",
    "    polygon = Polygon(points, closed=True, edgecolor='r', facecolor='r')\n",
    "    polygon_indices = np.array(points)\n",
    "    polygon_indices[:, 0] = np.clip(polygon_indices[:, 0], 0, 511)\n",
    "    polygon_indices[:, 1] = np.clip(polygon_indices[:, 1], 0, 511)\n",
    "    image_array[polygon_indices[:, 1], polygon_indices[:, 0]] = 1\n",
    "    polygon_path = Path(polygon_indices)\n",
    "    x, y = np.meshgrid(np.arange(512), np.arange(512))\n",
    "    points = np.column_stack((x.flatten(), y.flatten()))\n",
    "    mask = polygon_path.contains_points(points).reshape(512, 512)\n",
    "    image_array[mask] = 1\n",
    "\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, dir):\n",
    "        super().__init__()\n",
    "        self.dir = dir\n",
    "        self.images_path = join(dir, \"images\")\n",
    "        self.labels_path = join(dir, \"labels\")\n",
    "        self.images = os.listdir(self.images_path)\n",
    "        self.labels = os.listdir(self.labels_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx): # Return tuple (x, y)\n",
    "        try:\n",
    "            img = np.load(join(self.images_path, self.images[idx]), allow_pickle=True)\n",
    "            img = img.reshape(1, 512, 512) # Hard coded since all images are 512, 512\n",
    "\n",
    "            label = np.load(join(self.labels_path, self.labels[idx]), allow_pickle=True)\n",
    "            label = label.reshape(1, 512, 512)\n",
    "        except:\n",
    "            img, label = np.zeros((1,512,512), np.float32),np.zeros((1,512,512), np.float32)\n",
    "        return  img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CTDataset(\"Numpy Dataset\\\\train\")\n",
    "valid = CTDataset(\"Numpy Dataset\\\\valid\")\n",
    "test = CTDataset(\"Numpy Dataset\\\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDL = DataLoader(train, batch_size=CFG.batch_size,shuffle=True, pin_memory=True)\n",
    "validDL = DataLoader(valid, batch_size=CFG.batch_size)\n",
    "testDL = DataLoader(test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5331\n",
      "Valid: 1598\n",
      "Test: 616\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Valid: {len(valid)}\")\n",
    "print(f\"Test: {len(test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.relu  = ReLU()\n",
    "        self.conv2 = Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        # init random weights\n",
    "        nn.init.xavier_normal_(self.conv1.weight)\n",
    "        nn.init.zeros_(self.conv1.bias)\n",
    "\n",
    "        nn.init.xavier_normal_(self.conv2.weight)\n",
    "        nn.init.zeros_(self.conv2.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv2(self.relu(self.conv1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, channels = (1,32,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.pool = MaxPool2d((2,2))\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            Block(channels[i], channels[i+1]) for i in range(len(channels)-1) # 1, 32, ..., 1024\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = []\n",
    "        for block in self.encoder: # Goes through all blocks, passes through block and saves skip output\n",
    "            x = block(x)\n",
    "            skip_out.append(x)\n",
    "            x = self.pool(x) # Reduces dim\n",
    "        return skip_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDecoder(nn.Module):\n",
    "    def __init__(self, channels = (1,32,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.channels = channels[:0:-1] # Reverse of Encoder (Excluding First Unneeded in Output)\n",
    "        self.pool = MaxPool2d((2,2))\n",
    "        self.upconv = nn.ModuleList([\n",
    "            ConvTranspose2d(self.channels[i], self.channels[i+1], 2, 2) for i in range(len(self.channels)-1)\n",
    "        ])\n",
    "\n",
    "        self.decoder = nn.ModuleList([\n",
    "            Block(self.channels[i], self.channels[i+1]) for i in range(len(self.channels)-1)\n",
    "        ])\n",
    "\n",
    "    def center_crop(self, x, enc_out): # Crop encoder output\n",
    "        _, _, h, w = x.shape\n",
    "        enc_out = CenterCrop([h,w])(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def forward(self, x, enc_out:list):\n",
    "        for i in range(len(self.channels)-1):\n",
    "            x = self.upconv[i](x)\n",
    "            enc_ftrs = self.center_crop(x, enc_out[i]) # Crop Skip\n",
    "            x = torch.cat([x, enc_ftrs], dim=1) # Concatenate Decoder and Skip\n",
    "            x = self.decoder[i](x)\n",
    "\n",
    "            # Min Max Scaling [0,1]\n",
    "            x = (x-x.min())/(x.max()-x.min())\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self, channels = (1,32,64,128,256,512)):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder Path\n",
    "        self.enc_path = AutoEncoder(channels)\n",
    "\n",
    "        # Decoder Path\n",
    "        self.dec_path = AutoDecoder(channels)\n",
    "\n",
    "        self.out = Conv2d(channels[1], 1, 1)\n",
    "\n",
    "        # init random weights\n",
    "        nn.init.xavier_normal_(self.out.weight)\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skips = self.enc_path(x)\n",
    "        x = self.dec_path(skips[::-1][0], skips[::-1][1:]) \n",
    "        # Reverse of enc_out = upward path of decoder \n",
    "        #  [0] -> 1024 output\n",
    "        # [1:] -> All other skip outputs\n",
    "        x = self.out(x)\n",
    "        # x = F.interpolate(x, (512,512))\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.train_new:\n",
    "    try:\n",
    "        model = torch.load(f\"Models/{CFG.model_name}/{CFG.model_name}.pt\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model not found in models folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sørensen–Dice coefficient:\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)\n",
    "</br>\n",
    "$${\\displaystyle DSC={\\frac {2|X\\cap Y|}{|X|+|Y|}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diceCoef(nn.Module):\n",
    "    def init(self):\n",
    "        super(diceCoef, self).init()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):   \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):   \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #intersection is equivalent to True Positive count\n",
    "        #union is the mutually inclusive area of all labels & predictions \n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = (inputs + targets).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "                \n",
    "        return 1 - IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, ALPHA = 0.5, BETA = 0.5):\n",
    "        super(TverskyLoss, self).__init__()\n",
    "        self.alpha = ALPHA\n",
    "        self.beta = BETA\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = (inputs * targets).sum()    \n",
    "        FP = ((1-targets) * inputs).sum()\n",
    "        FN = (targets * (1-inputs)).sum()\n",
    "       \n",
    "        Tversky = (TP + smooth) / (TP + self.alpha*FP + self.beta*FN + smooth)  \n",
    "        \n",
    "        return 1 - Tversky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_dice = DiceBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_iou = IoULoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bce = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_tversk = TverskyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7759521 Trainable Parameters'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "f\"{get_n_params(model)} Trainable Parameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDL = DataLoader(train, batch_size=16, shuffle=True)\n",
    "validDL = DataLoader(valid, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,  criterion, optim, scheduler):      \n",
    "    train_loss = 0\n",
    "    bce_loss = 0\n",
    "    iou_loss = 0\n",
    "    dice_loss = 0\n",
    "    for x,y in tqdm(trainDL):\n",
    "        x, y = x.to(CFG.device), y.to(CFG.device)\n",
    "        optim.zero_grad()\n",
    "        with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "            pred = checkpoint(model, x).detach()\n",
    "            loss = criterion(pred, y)\n",
    "            loss = Variable(loss, requires_grad=True)\n",
    "            \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss += loss\n",
    "        del x,y,pred,loss\n",
    "    \n",
    "    \n",
    "    # eval\n",
    "    with torch.no_grad():\n",
    "        for x,y in validDL:\n",
    "            x, y = x.to(CFG.device), y.to(CFG.device)\n",
    "            pred = model(x).detach()\n",
    "            loss_bce = criterion_bce(pred, y)\n",
    "            loss_dice = criterion_dice(pred,y)\n",
    "            loss_iou = criterion_iou(pred, y)\n",
    "            bce_loss += loss_bce\n",
    "            iou_loss += loss_iou\n",
    "            dice_loss += loss_dice\n",
    "    \n",
    "    scheduler.step(bce_loss)\n",
    "        \n",
    "    avg_train_loss = train_loss/len(trainDL)\n",
    "    avg_bce_loss = bce_loss/len(validDL)\n",
    "    avg_iou_loss = iou_loss/len(validDL)\n",
    "    avg_dice_loss = dice_loss/len(validDL)\n",
    "\n",
    "    \n",
    "    print(f\"Train Loss: {avg_train_loss}\")\n",
    "    print(f\"Validation BCE Loss: {avg_bce_loss}\")\n",
    "    print(f\"Validation Dice Loss: {avg_dice_loss}\")\n",
    "    print(f\"Validation IOU Loss: {avg_iou_loss}\")\n",
    "    return avg_train_loss, avg_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(criterion, init_lr = 0.1, name = \"model\"):\n",
    "    model = UNET().to(CFG.device)\n",
    "    model.train()\n",
    "\n",
    "    optim = AdamW(model.parameters(), lr=init_lr)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optim, factor=0.5, min_lr=0.0001, verbose=True)\n",
    "\n",
    "\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "\n",
    "    for e in range(CFG.nEpochs):\n",
    "        print(f\"\\n\\n[INFO] Epoch {e+1}/{CFG.nEpochs}\")\n",
    "        train_loss, val_loss = train_epoch(model, criterion, optim, scheduler)\n",
    "        train_hist.append(float(train_loss.detach().cpu()))\n",
    "        val_hist.append(float(val_loss.detach().cpu()))\n",
    "\n",
    "    if not os.path.exists(f\"Models/{name}\"):\n",
    "        os.mkdir(f\"Models/{name}\")\n",
    "    torch.save(model.state_dict(), f\"Models/{name}/model.pt\")\n",
    "\n",
    "    history = pd.DataFrame({\"train\":train_hist, \n",
    "                         'validation':val_hist}, index = range(1,len(train_hist)+1))\n",
    "    \n",
    "    history.to_csv(f\"Models/{name}/logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0.77,0.9]:\n",
    "#     criterion = TverskyLoss(ALPHA = i, BETA=1-i)\n",
    "#     run_model(criterion, name=f\"Tversky2-{round(i,2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNET().to(CFG.device)\n",
    "model.load_state_dict(torch.load(\"Models\\Tversky2-0.9\\model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(img_num = None, th=98, upper=100):\n",
    "    if not img_num:\n",
    "        img_num = random.randint(1, len(test))\n",
    "\n",
    "    print(f\"Image Number: {img_num}\")\n",
    "\n",
    "    img = test[img_num][0]\n",
    "    label = test[img_num][1]\n",
    "\n",
    "    inference_img = torch.Tensor(img).to(CFG.device).reshape(1,1,512,512)\n",
    "    model.eval()\n",
    "    inference = model(inference_img)\n",
    "    inf = inference.squeeze().detach().cpu().numpy()\n",
    "    inf2 = (inf-inf.min())/inf.max()\n",
    "    inf2 = inf2*img.squeeze()\n",
    "    th = np.percentile(inf2.flatten(), th)\n",
    "\n",
    "    fig,ax = plt.subplots(1,4,figsize=(15,15))\n",
    "\n",
    "    ax[0].imshow(img.transpose(1,2,0), cmap='gray')\n",
    "    ax[0].axis(False)\n",
    "    ax[0].set_title(\"Image\", fontsize=10)\n",
    "\n",
    "    ax[1].imshow(inf2>th, cmap='gray')\n",
    "    ax[1].axis(False)\n",
    "    ax[1].set_title(\"Prediction\", fontsize=10)\n",
    "\n",
    "    ax[2].imshow(label.squeeze(), cmap='gray')\n",
    "    ax[2].axis(False)\n",
    "    ax[2].set_title(\"Label\", fontsize=10)\n",
    "\n",
    "    pred1 = (inf2>th)\n",
    "    pred2 = (inf2<upper)\n",
    "    pred = pred1*pred2\n",
    "\n",
    "    overlay = (img*0.1).squeeze()\n",
    "    overlay = np.stack([overlay, overlay, overlay]).transpose(1,2,0)\n",
    "    overlay[:,:,1] = overlay[:,:,1] + (label.squeeze() * img.squeeze()).squeeze()*0.2  # Red\n",
    "    overlay[:,:,0] = overlay[:,:,0] + (pred.squeeze() * label.squeeze()).squeeze() # Green\n",
    "    ax[3].imshow(overlay)\n",
    "    ax[3].axis(False)\n",
    "    ax[3].set_title(\"Accuracy\", fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     run_inference(th=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_dice = diceCoef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE: 0.7894912362098694\n",
      "DICE: 0.9996675848960876\n",
      "IOU: 0.9998223185539246\n"
     ]
    }
   ],
   "source": [
    "bce_loss = 0\n",
    "iou_loss = 0\n",
    "dice_loss = 0\n",
    "with torch.no_grad():\n",
    "    for x,y in testDL:\n",
    "        x, y = x.to(CFG.device), y.to(CFG.device)\n",
    "        pred = model(x).detach()\n",
    "        pred = pred*x\n",
    "        loss_bce = criterion_bce(pred, y)\n",
    "        loss_dice = criterion_dice(pred,y)\n",
    "        loss_iou = criterion_iou(pred, y)\n",
    "        bce_loss += loss_bce\n",
    "        iou_loss += loss_iou\n",
    "        dice_loss += loss_dice\n",
    "BCE_LOSS = bce_loss/len(testDL)\n",
    "DICE_LOSS = dice_loss/len(testDL)\n",
    "IOU_LOSS = iou_loss/len(testDL)\n",
    "print(f\"BCE: {BCE_LOSS}\")\n",
    "print(f\"DICE: {DICE_LOSS}\")\n",
    "print(f\"IOU: {IOU_LOSS}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_images = []\n",
    "for i in range(100):\n",
    "    img = test[i][0]\n",
    "    img = torch.Tensor(img).to(CFG.device).reshape(1,1,512,512)\n",
    "    inf_images.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in inf_images:\n",
    "    model(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
